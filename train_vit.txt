J'entraîne un modèle ViT-B16 pré-entraîné. Je commence par un entraînement exploratoire de 20 époques pour analyser la convergence et les performances sur notre base de test. Ensuite, je réalise un entraînement complet sur toute la base avec 50 époques, un batch size de 4, et une image size de 224×224 (dimension d’entrée du ViT pré-entraîné sur ImageNet). J’utilise la CrossEntropyLoss, adaptée à la classification multi-classe, car elle mesure efficacement l’écart entre la prédiction softmax et la vraie classe, ce qui est idéal lorsque chaque image appartient à une seule classe.