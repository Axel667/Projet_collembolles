{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_label_Dataset(Dataset):\n",
    "    def __init__(self, images_dir, csv_file, fallback_csv, transform=None, split=\"train\", seed=42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (string): Dossier contenant les images.\n",
    "            csv_file (string): Chemin vers le fichier CSV contenant les informations principales.\n",
    "            fallback_csv (string): Chemin vers le fichier CSV contenant image_id + bbox + final_label.\n",
    "            transform (callable, optional): Transformations à appliquer aux images.\n",
    "            split (string): \"train\" ou \"test\" pour choisir le dataset.\n",
    "            seed (int): Pour rendre la répartition fixe.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.seed = seed\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.fallback_data = pd.read_csv(fallback_csv)\n",
    "        self.boxes = self._create_boxes_list()\n",
    "\n",
    "        self._split_data()\n",
    "        self.class_counts = self.count_classes()\n",
    "\n",
    "    def _create_boxes_list(self):\n",
    "        \"\"\"\n",
    "        Crée une liste de dictionnaires où chaque boîte est une entrée unique.\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        for _, row in self.data.iterrows():\n",
    "            image_id = str(row['id'])\n",
    "            bbox = [row['xc'], row['yc'], row['w'], row['h']]\n",
    "            avis = row['avis']\n",
    "            label = self.avis_majoritaire(avis)\n",
    "            \n",
    "            if label is None:\n",
    "                label = self.get_fallback_label(image_id, bbox)\n",
    "            \n",
    "            if label not in [None, 8]:  \n",
    "                boxes.append({\n",
    "                    'image_id': image_id,\n",
    "                    'bbox': bbox,\n",
    "                    'label': label\n",
    "                })\n",
    "        return boxes\n",
    "\n",
    "    def get_fallback_label(self, image_id, bbox):\n",
    "        \"\"\"\n",
    "        Cherche le label dans le fichier CSV de fallback si avis_majoritaire retourne None.\n",
    "        \"\"\"\n",
    "        # Convertir la chaîne de caractères du 'bbox' du fichier fallback en tuple\n",
    "        self.fallback_data['bbox_tuple'] = self.fallback_data['bbox'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "        # Arrondir le bbox à 5 décimales pour correspondre au format du fichier fallback\n",
    "        bbox_round = tuple(round(val, 5) for val in bbox)\n",
    "\n",
    "        # Recherche d'une correspondance\n",
    "        match = self.fallback_data[(self.fallback_data['idx'] == image_id) & \n",
    "                                    (self.fallback_data['bbox_tuple'] == bbox_round)]\n",
    "\n",
    "        if not match.empty:\n",
    "            return int(match.iloc[0]['final_label'])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _split_data(self):\n",
    "        \"\"\"\n",
    "        Effectue le split de l'ensemble de données en train et test.\n",
    "        \"\"\"\n",
    "        labels = [box[\"label\"] for box in self.boxes]\n",
    "        train_data, test_data = train_test_split(self.boxes, test_size=0.4, random_state=self.seed, stratify=labels)\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            self.data_split = train_data\n",
    "        elif self.split == \"test\":\n",
    "            self.data_split = test_data\n",
    "        else:\n",
    "            raise ValueError(\"Split must be one of ['train', 'test']\")\n",
    "\n",
    "    def count_classes(self):\n",
    "        \"\"\"\n",
    "        Compte le nombre d'instances pour chaque classe dans le dataset actuel.\n",
    "        \"\"\"\n",
    "        class_counts = defaultdict(int)\n",
    "        for annotation in self.data_split:\n",
    "            label = annotation['label']\n",
    "            class_counts[label] += 1\n",
    "        return dict(class_counts)\n",
    "\n",
    "    def avis_majoritaire(self, avis, min_count=4):\n",
    "        \"\"\"Calcule l'avis majoritaire uniquement s'il dépasse un seuil minimal.\"\"\"\n",
    "        parts = avis.split('_')\n",
    "        count = Counter(parts)\n",
    "        \n",
    "        majoritaire, occurrences = max(count.items(), key=lambda x: x[1])\n",
    "        \n",
    "        if occurrences >= min_count:\n",
    "            return int(majoritaire)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_split)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retourne une image découpée selon la boîte englobante et son label.\n",
    "        \"\"\"\n",
    "        annotation = self.data_split[idx]\n",
    "        bbox = annotation['bbox']\n",
    "        label = annotation['label']\n",
    "\n",
    "        image_path = os.path.join(self.images_dir, f\"{annotation['image_id']}.jpg\")\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        xc, yc, w, h = bbox\n",
    "        x_min = int((xc - w / 2) * image.width)\n",
    "        x_max = int((xc + w / 2) * image.width)\n",
    "        y_min = int((yc - h / 2) * image.height)\n",
    "        y_max = int((yc + h / 2) * image.height)\n",
    "\n",
    "        cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "        if self.transform:\n",
    "            cropped_image = self.transform(cropped_image)\n",
    "            \n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        return cropped_image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_label = Image_label_Dataset(images_dir=img_dir, csv_file=csv_file, fallback_csv=label_csv, transform=transform, split='train')\n",
    "test_dataset_label = Image_label_Dataset(images_dir=img_dir, csv_file=csv_file, fallback_csv=label_csv, transform=transform, split='test')\n",
    "\n",
    "train_background = BackgroundDataset(img_dir, csv_file, transform=transform, num_samples=int(mean(train_dataset.class_counts.values())))\n",
    "test_background = BackgroundDataset(img_dir, csv_file, transform=transform, num_samples=int(mean(test_dataset.class_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_background = torch.utils.data.ConcatDataset([train_dataset_label, train_background])\n",
    "test_data_background = torch.utils.data.ConcatDataset([test_dataset_label, test_background])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_background = torch.utils.data.ConcatDataset([train_data_background, test_data_background])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
